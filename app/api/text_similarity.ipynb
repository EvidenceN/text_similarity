{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing regex\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text samples\n",
    "\n",
    "sample1 = \"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
    "\n",
    "sample2 = \"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n",
    "\n",
    "sample3 = \"We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and establishing stop words\n",
    "\n",
    "with open(\"stopwords.txt\", 'r') as s:\n",
    "    stop_words = s.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pre-process the data\n",
    "\n",
    "def text_processing(sample):\n",
    "    \"\"\"\n",
    "    A function to pre-process the text\n",
    "\n",
    "    - Lower the text\n",
    "    - Remove punctuation from the text\n",
    "    - remove stop words\n",
    "    - tokenize the text\n",
    "    \"\"\"\n",
    "    # Can't do accurate lemmetization or stemming without a library or spending months accounting for every vocabulary, So no lemmetization or stemming technique used. \n",
    "    \n",
    "    # lower the text\n",
    "    sample = sample.lower()\n",
    "\n",
    "    # use regex to remove anything that is not words and numbers\n",
    "    sample = re.sub(r\"[^a-zA-Z0-9]\", \" \", sample) \n",
    "\n",
    "    # tokenize text\n",
    "    sample = sample.split()\n",
    "\n",
    "    # remove stop words\n",
    "    sample = [word for word in sample if word not in stop_words]\n",
    "\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the text\n",
    "\n",
    "sample1_p = text_processing(sample1)\n",
    "sample2_p = text_processing(sample2)\n",
    "sample3_p = text_processing(sample3)"
   ]
  },
  {
   "source": [
    "Do TF-IDF calculation for each document sample, Then use this to calculate the cosine similarity number. Which will give us a value of how similar the 2 text documents are. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A function for calculating term frequency\n",
    "\n",
    "def term_frequency(processed_text):\n",
    "    \"\"\"\n",
    "    This function will calculate the term frequency of every word in the document\n",
    "\n",
    "    The input is the pre-process text that is already tokenized\n",
    "\n",
    "    The output is the frequency of each word divided by total number of words \n",
    "    \"\"\"\n",
    "\n",
    "    total_word_count = len(processed_text)\n",
    "\n",
    "    # individual word count\n",
    "    word_count = dict(Counter(processed_text))\n",
    "\n",
    "    # calculating term frequency (tf)\n",
    "    tf = {}\n",
    "\n",
    "    for word, count in word_count.items():\n",
    "        tf[word] = round(count/total_word_count, 4)\n",
    "\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating term frequency for each word\n",
    "\n",
    "tf_s1 = term_frequency(sample1_p)\n",
    "tf_s2 = term_frequency(sample2_p)\n",
    "tf_s3 = term_frequency(sample3_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is comparing only 2 texts, the Inverse Document Frequency (IDF) will be for only 2 documents, not all 3 of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Inverse Document Frequency for 2 documents. \n",
    "# doing IDF for all 3 samples doesn't make sense because the final \n",
    "# product will calculate IDF for only 2 samples inputed as the \"POST Method\"\n",
    "\n",
    "def idf(doc1, doc2):\n",
    "    \"\"\"\n",
    "    Calculate the inverse document frequency assuming only 2 documents\n",
    "    \n",
    "    Input is the 2 documents in questions\n",
    "\n",
    "    Output will be the IDF of the words in both documents\n",
    "    \"\"\"\n",
    "\n",
    "    # convert each document into a set. \n",
    "    set_1 = set(doc1)\n",
    "    set_2 = set(doc2)\n",
    "\n",
    "    # find word that occurs in both documents\n",
    "    words_in_both_docs = set_1 & set_2\n",
    "\n",
    "    # find word that occurs only once in either document\n",
    "    words_in_only_one_doc = set_1 ^ set_2\n",
    "\n",
    "        # number of documents. In this case, we know only 2 documents will be used for comparison. No need to account for comparing more than 2 documents. \n",
    "\n",
    "    number_of_doc = 2\n",
    "\n",
    "    # creating a dictionary of the document frequency of the term\n",
    "    # document frequency is number_of_doc/term_frequency_in_document\n",
    "    # inverse document frequency is log(document frequency)\n",
    "\n",
    "    doc_freq = {}\n",
    "\n",
    "    for word in words_in_both_docs:\n",
    "        doc_freq[word] = round(math.log(number_of_doc/2), 2)\n",
    "\n",
    "    for word in words_in_only_one_doc:\n",
    "        doc_freq[word] = round(math.log(number_of_doc/1), 4)\n",
    "\n",
    "    return doc_freq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse term frequeny of sample 1 and sample 2\n",
    "s1_s2_idf = idf(sample1_p, sample2_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse term frequeny of sample 1 and sample 3\n",
    "s1_s3_idf = idf(sample1_p, sample3_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse term frequeny of sample 3 and sample 3\n",
    "s2_s3_idf = idf(sample3_p, sample3_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming calculating the TF-IDF for only 2 documents of interest and not the entire sample set. \n",
    "\n",
    "def tf_idf(tf, idf):\n",
    "    \n",
    "    tf_idf = {}\n",
    "    \n",
    "    for word, value in tf.items():\n",
    "        tf_idf[word] = round(value * idf[word], 4)\n",
    "\n",
    "    return tf_idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample 1 & sample 2- tf-idf score \n",
    "# Assuming only sample 1 and sample 2 make up the entire corpus\n",
    "\n",
    "tf_idf1 = tf_idf(tf_s1, s1_s2_idf)\n",
    "\n",
    "tf_idf2 = tf_idf(tf_s2, s1_s2_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample 1 & sample 3 tf-idf score \n",
    "# Assuming only sample 1 and sample 3 make up the entire corpus\n",
    "\n",
    "tf_idf1_3 = tf_idf(tf_s1, s1_s3_idf)\n",
    "\n",
    "tf_idf3 = tf_idf(tf_s3, s1_s3_idf)\n"
   ]
  },
  {
   "source": [
    "Use Cosine Similarity to find the similarity between 2 pieces of text. \n",
    "\n",
    "Formula: cosÎ¸ = v1.v2 / ( |v1| * |v2| )\n",
    "\n",
    "v1 = tf-idf of sample 1\n",
    "\n",
    "v2 = tf-idf of sample 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cosine similarity between sample 1 and sample 2\n",
    "\n",
    "# sample 1 tf-idf assuming only sample 1 and sample 2 in corpus\n",
    "tf_idf1\n",
    "\n",
    "# sample 2 tf-idf assuming only sample 1 and sample 2 in corpus\n",
    "tf_idf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cosine similarity between sample 1 and sample 3\n",
    "\n",
    "# Assuming only sample 1 and sample 3 make up the entire corpus\n",
    "\n",
    "# sample 1 tf-idf assuming only sample 1 and sample 3 in corpus\n",
    "tf_idf1_3 \n",
    "\n",
    "# sample 3 tf-idf assuming only sample 1 and sample 3 in corpus\n",
    "tf_idf3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "len(list(tf_idf1.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "len(list(tf_idf2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating cosine similarity\n",
    "\n",
    "def cosine(tf_idf1, tf_idf2):\n",
    "    \"\"\"\n",
    "    The input value are the 2 tf-idf dictionary for each sample. \n",
    "\n",
    "    the values from dictionary values which are the vectors will be used\n",
    "    to calculate the dot product of both vectors and the magnitude of each \n",
    "    vector in order to get the cosine similarity value. \n",
    "\n",
    "    The output will be the cosine similarities between the 2 samples\n",
    "    \"\"\"\n",
    "    # get the values from the tf_idf dictionary\n",
    "    v1 = list(tf_idf1.values())\n",
    "    v2 = list(tf_idf2.values())\n",
    "\n",
    "    # calculate dot product from both vectors\n",
    "    dotproduct=0\n",
    "\n",
    "    for a,b in zip(v1,v2):\n",
    "        dotproduct = dotproduct+a*b\n",
    "\n",
    "    # calculate magnitude of each vector\n",
    "\n",
    "    # magnitude of v1\n",
    "    mag_v1 = math.sqrt(sum(pow(element, 2) for element in v1))\n",
    "    \n",
    "    # magnitude of v2\n",
    "    mag_v2 = math.sqrt(sum(pow(element, 2) for element in v2))\n",
    "\n",
    "    # now combine dot product and magnitude to get cosine similarity value\n",
    "\n",
    "    cosine_similarity = round(dotproduct/(mag_v1 * mag_v2), 2)\n",
    "\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# similarity score between sample 1 and sample 2\n",
    "cosine(tf_idf1, tf_idf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "# similarity score between sample 1 and sample 3\n",
    "cosine(tf_idf1, tf_idf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}